---
title: 'Flying Blind: Education Reform in Latin America in the 1990s'
author: "Thomas R. Vargas^[Corresponding address:
  varga081@umn.edu. I thank Teri Caraway, Brent Edwards, John Freeman, Carly Potz-Nielsen, Claire Le Barebenchon, Dave Lopez, and David Samuels for their comments on previous drafts of this papers. A previous version of this paper was presented at the University of Minnesota and the Midwest Political Science Association Meeting. Any remaining mistakes are my own.]"
abstract: \singlespacing Conventional wisdom suggests that Latin American countries reformed public education in the 1990s in response to a crisis of coverage and quality.  Yet, in terms of access, Latin American countries had achieved relatively high enrolment and completion rates by 1990.  With regards to quality, there was simply no high-quality evidence showing weak or lowering standards. In short, by the early 1990s, there was very little scientific evidence of a crisis of public education in Latin America. By uncovering these patterns, this paper argues that political scientist should revisit the origins of education reform efforts in the 1990s.  
date: 'Accepted at the *International Journal of Educational Reform*.'
bibliography: bib.bib
mainfont: Times New Roman
sansfont: Times New Roman
colorlinks: true
documentclass: article
geometry: margin=1in
fontsize: 12pt
linestretch: 1.5
link-citations: true
output:
  pdf_document: 
        includes:
          in_header: header.tex
        number_sections: true
  html_document: default
  word_document: 
    reference_docx: word-template.docx
---
\newpage 

# Introduction 

Since the establishment of modern public education systems in Latin America in the mid-twentieth century, governments have proposed and executed reforms of all types. For example, countries have long wrestled with changes to curricula, hiring standards for teachers, and expenditures on education. But following the 1980s debt crisis and the adoption of democracy and economic liberalization around the same time, changes to public education accelerated. For the first time a region-wide conversation regarding the governance of education systems came to the table.^[I define the governance of education systems as the institutional arrangements that describe who has authority over the management of public schools. In the Latin America of the 1990s these changes generally meant decentralization—for example, via the devolution of schools to subnational states (e.g., Mexico), the co-management of schools with municipalities (e.g., Colombia), and the establishment of schools managed directly by the local community (e.g., El Salvador), among others.] Figure 1 plots the rate of adoption of governance reforms in the education sector in Latin America from 1989 through 2005. Why did so many Latin American countries jump on the reform bandwagon?

```{r, fig1_dataload, include=FALSE, cache=F}
#Packages
library(ggplot2)

# Load data
sum_name<-read.csv("data/decentral_sum.csv")

fig1<-ggplot(sum_name, aes(x=year, y=decentralized_countries))+
            geom_step(size = 1.25) +
            theme_bw() +
            labs(y="Cumulative Adoption",
                 x="Year",
                 caption = "Source: Vargas 2018.") +
            scale_x_continuous(breaks = seq(1990,2000,2)) +
            coord_cartesian(xlim=c(1990,2000))
```

```{r, plotfig1, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, fig.cap = "Rate of Adoption of Education Governance Reforms in Latin America", fig.width=3.5, fig.height=3, cache=F}
fig1
```

The conventional answer to this question is straightforward: education in Latin America, to paraphrase Merilee @grindle_despite_2004, was broken. Specifically, reform advocates pointed to high dropout rates, gender and income inequality in access to education, inefficient public spending, and low quality of education [@birdsall_education_1998; @idb_facing_1998; @preal_lagging_2001; @reimers_role_1997; @reimers_impact_1991]. The political science literature has taken this premise mostly as a given [@grindle_despite_2004;@kaufman_crucial_2004; @pribble_welfare_2013], focusing instead on the politics of reform implementation [@corrales_politics_1999; @graham_improving_1999]. But was the provision of public education across the region truly so dismal? The purpose of this paper is to answer this question by looking at the evidence available to policymakers in the 1990s.

Contrary to this picture of a widespread education sector catastrophe, by the early 1990s Latin America’s public education systems had made substantial achievements in the face of difficult circumstances. The education systems of the region improved access to education in every country, across many subgroups, despite a decade-long recovery from the debt crisis. Characterizing the state of education in Latin America as dismal requires making use of “snapshot” statistics. A cross-sectional analysis of literacy rates in the early 1990s would obscure the fact that between 1950 and 1990 these countries reduced illiteracy rates from 49% to 14.5%, a rate of about one percentage point per year, even as the population was growing [@idb_economic_1996].

On other fronts, such as the quality of education, the evidence was less encouraging. Still, by 1993 there were simply no cross-time, systematically collected, nationally representative data on the amount of learning being done in the region.^[Historically, there have been several attempts to centralize and beef-up the supervision of Latin American education systems. For example, it is well known that countries throughout the region conducted education census (*censos*) as early as the 19th Century. Yet, the modern evaluation systems that would allow the measurement of student performance, popular in rich countries, would come to Latin America quite late.] In short, while the available evidence suggested to policymakers a mixed bag of successes and challenges, it did not show an unmitigated catastrophe.

Understanding these issues is important beyond offering a new theoretical perspective. Knowing why and when governments move to reform education is especially urgent in the developing world because a vast scholarship supports the notion that education is key to achieving long-run economic growth and higher standards of living [@galor_inequality_2009; @glewwe_improving_2016]. And while governments should be open to improving and changing their public education systems, advocates for system improvement should be clear-eyed about the reasons that governments acquiesce. To be sure, there is a place for democratic politics in the process of determining social policy, but it is an analytic oversight to assume that reforms are always needed or positive, that reform advocates have the best of intentions, and that opponents are the “bad guys.”^[Perhaps this is the reason that so much emphasis has been placed on teachers' unions as intransigent veto players [@moe_comparative_2016].]

The remainder of this paper is divided into four sections. The first two examine the sort of evidence that was available to reform advocates by the 1990s with regard to both the coverage and quality of education. By placing data in a historical context, I show unambiguous improvements in the coverage of education. I also examine the limited evidence available with regard to the quality of education. In the third section I give conventional wisdom the benefit of the doubt. In a generous reading of its implications, I ask: were the governments with the weakest performance across a range of education indicators likelier to reform than the rest? Using simple quantitative tools on unmodeled data, I find no evidence that this was the case. The fourth section concludes by proposing some avenues for future research.

# The State of Education: Coverage

Let us examine the state of education in Latin America by the 1990s. Consider first the question of access: did Latin America’s education systems fail to expand the coverage of primary education over time? In short, no; coverage saw across the board improvements even while Latin America was recovering from the debt crisis.

```{r, fig2_dataload, include=FALSE, cache=F}
#Packages
# Load data
library(tidyverse)
qog<-read_csv("data/qog_std_ts_jan19.csv") %>%
  select(ccode, cname, year, wdi_gerpf, wdi_nerpf, ccodecow, ccodealp,
         wdi_expedu, bl_asymf, bl_lpf, bl_lpmf, gea_ea1524f, gea_ea1524m,
         wdi_gerp, wdi_expedup, ht_region, gle_cgdpc, gle_rgdpc)
write_csv(qog, "data/qog_std_ts_jan19.csv")

hist(qog$ht_region)

fig2a<-qog %>%
  filter(ht_region==2) %>%
  group_by(year) %>%
  summarise(ave = mean(wdi_gerpf,na.rm = TRUE),
            min = min(wdi_gerpf,na.rm = TRUE)) %>%
  pivot_longer(-year, names_to = "type", values_to = "y") %>%
  ggplot(aes(x=year, y=y, group=type, color=type, linetype=type)) +
    scale_color_discrete(name="Line",
                       breaks = c("ave", "min"),
                       labels = c("Average", "Minimum")) +
      scale_linetype_discrete(name="Line",
                       breaks = c("ave", "min"),
                       labels = c("Average", "Minimum")) +
    geom_line() +
    xlim(1970,2000) +
    ylim(40,120) +
    theme_bw() +
    theme(legend.title = element_blank(),
          legend.position = c(0.8, 0.2))+
      labs(title="Primary School Enrollment Rates",
         x="Year",
         y="Gross Share (%)")

data_global<-qog %>%
  filter(ht_region!=2) %>%
  group_by(year) %>%
  summarise(ave = mean(wdi_nerpf,na.rm = TRUE)) %>%
  mutate(type="global")

data_lac<-qog %>%
  filter(ht_region==2) %>%
  group_by(year) %>%
  summarise(ave = mean(wdi_nerpf,na.rm = TRUE)) %>%
  mutate(type="lac")

data_together<-rbind(data_global, data_lac)

fig2b<-ggplot(data_together, aes(x=year, y=ave, group=type, color=type, linetype=type)) +
    geom_line() +
    scale_color_discrete(name="Line",
                       breaks = c("global", "lac"),
                       labels = c("Global", "LAC")) +
      scale_linetype_discrete(name="Line",
                       breaks = c("global", "lac"),
                       labels = c("Global", "LAC")) +
    geom_line() +
    xlim(1970,2000) +
    ylim(65,100) +
    theme_bw() +
    theme(legend.title = element_blank(),
          legend.position = c(0.8, 0.2))+
    labs(title="Primary School Completion Rates",
         x="Year",
         y="Gross Share (%)")


library(gridExtra)
```

```{r, plotfig2, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, fig.cap = "Enrollment and Completion Rates in Latin America", fig.width=8, fig.height=4, cache=F}
grid.arrange(fig2a,fig2b, ncol=2)
```

The left panel of Figure 2 graphs average gross enrollment rates (GER) in primary education for Latin America in red, and the GER for the poorest-performing country in the region in green.^[Data are drawn from the United Nations Educational, Scientific, and Cultural Organization (UNESCO) Institute for Statistics.4 Enrollment rates are defined as “the ratio of total enrollment, regardless of age, to the population of the age group that officially corresponds to the level of education shown,” whereas completion rates are given by “the number of new entrants (...minus repeaters) in the last grade of primary education, regardless of age, divided by the population at the entrance age for the last grade of primary education.” The practical distinction between both measures is that enrollment rates can exceed 100% because they include children who start early or repeat grades.] The left panel presents a generally rosy picture of education: by the 1990s public education had achieved a high level of coverage. This is especially true for the worst-performing countries. From 1970 to 2000 the lowest enrollment rate in the region shot up by nearly 40 percentage points, from under 60% to about 100%. However, since enrollment rates do not account for children repeating grades or starting late, the left panel is consistent with not only improving coverage but also, for example, declining completion rates. For instance, it is possible that economic circumstances made schooling more difficult or costly for Latin American households, generating more grade repeaters or late starters.^[The precise effect of aggregate negative income shocks on household schooling decisions is ambiguous because of competing income and substitution effects [@binder_schooling_1999;@ferreira_aggregate_2009]).]

The right panel of Figure 2 showcases average completion rates for Latin America in green, low- and middle-income economies in blue, and the world in red. Notice that the average trend in completion rates in the right panel tracks the enrollment rates in the left panel quite closely. This suggests that the trends in the left panel reflect an underlying improvement in completion rates over time. In general, the evidence shows that over time the number of children enrolling in and completing school has, on average, grown since the 1970s. Second, while it is true that completion rates stagnated during the 1980s, they did so at fairly high levels—around 90%. Overall, this points to well-performing education systems.

These gains in coverage extend also to women. Figure 3 looks at coverage rates for women from 1970 through 2000. The left panel examines GERs for primary education for the average Latin American case in red and the lowest regional enrollment rate in blue. The average enrollment rate for women in the region was quite high by the 1970s, and while there was a small dip in the first half of the 1980s, it recovered by the second half. Improvements for the worst-performing Latin American country are quite dramatic. By the 1980s the weakest enrollment rate for women was around 60%, but by the end of the decade it was almost 90%. While there was a significant dip in the first half of the 1990s, this drop did not entirely reverse the gains of the 1980s. In short, enrollment figures for women did not seem to take a particularly hard hit in the 1980s.^[Unfortunately, there are no completion data available by gender, though there are some other historical statistics I will consider shortly. In any case, our exploration of the relationship between enrollment and completion rates suggests that these two statistics track each other closely. This implies that completion rates for girls also improved over time.] The right panel examines average years of schooling for women over 15 years of age.^[The data are compiled every five years and are shown in red for Latin America as a whole and in blue for the worst-performing countries.] The average number of years of schooling for women in Latin American countries also increased across the board.

A final question relates to Latin America’s performance from a comparative perspective. Did Latin America’s education systems fail to expand the coverage of primary education compared to countries in other regions? The short answer is no. Figure 4 presents three plots that compare Latin American countries to other countries at similar levels of GDP per capita. The plots contain two LOESS regression lines: in blue I plot the worldwide average; in red I plot the developing country average, dropping Latin America from the sample.^[I subset the data to include an average for countries in North Africa and the Middle East, Sub-Saharan Africa, Southeast Asia, South Asia, and the Caribbean (including Belize, Guyana, and Suriname, but excluding Cuba, Haiti, and the Dominican Republic).] The dots represent Latin American observations only from 1970 to 1995.^[For readability I make two adjustments. I remove the standard errors and I scale the x-axis to reflect only the span of Latin American countries in the sample. Since the regression lines are local, there should be no concerns regarding any conclusions from the plots.]

Across all panels Latin American countries seem to perform at or above both global and developing world averages. I discuss them clockwise from the top left. The first panel shows that Latin American gross enrollment rates are very high at all levels of income. Generally, the region seems to beat world averages when it comes to enrollment. The top right panel compares educational attainment in Latin America to that of the rest of the world. The measure of educational attainment I plot is from @barro_new_2013, and measures the average years of schooling for male and female adults over 25 years of age. The distribution of Latin American observations is less tight than in the previous plot, but it appears that Latin American countries show a normal variation compared to the global average, and appear to do better than most developing countries. However, some countries do significantly worse than those averages. The third panel looks at average years of schooling for females by age 25. Latin American countries track global averages quite closely and generally outperform other countries. Again, this is true at all levels of income.

Latin America’s performance is all the more notable considering that the region endured the lasting effects of the debt crisis. What followed was a period of structural adjustment and openness to international markets. Both of these trends have been associated with pressures to cut social spending [@kaufman_globalization_2001;@garrett_globalization_2001;@reimers_impact_1991;@reimers_education_1994]. We cannot know what would have happened to enrollment and completion rates in the absence of the debt crisis; it is plausible, for example, that they would have grown at higher rates. Yet this is not the argument that reform advocates made. They contended that coverage was bad, especially for women and subgroups. As reviewed, the data do not support this conclusion. Rather than systems in crisis of access, the untold story of the 1980s might be that the region experienced no reversals in coverage during the “lost decade” and instead maintained average levels of spending on primary education. Perhaps most importantly, while gains in enrollment were uneven across countries, the countries with the lowest enrollment rates made the most substantial gains.

# The State of Education: Quality

What about the quality of education? In Latin America the notion that the quality of public education is low is widespread.^[This is a well-known trope among education specialist in the region. It also makes its way very often to editorials and news articles across every country in the region [@villareal_es_2018;@la_nacion_necesidad_2015;@molina_educacion_2007;@moreno_apos_2017] and numerous reports by international organizations since the early 1990s [@szekely_educacion_2012;@wolff_improving_1994].] To give an example, the sub-heading of a 1994 report by the Costa Rican Ministry of Education reads, “The Collapse of Costa Rican Education” [@mep_marco_1994]. Similarly, the World Bank, UNESCO, and the Inter-American Development Bank (IDB) continuously call attention to the dangerously low quality of education and fund dozens of programs each year focused on improving the quality of education. The IDB alone has 116 active education sector projects in the implementation phase across the region, spending over $2 billion since 2010. Of these funds, over $800 million is earmarked for quality of education projects.^[These are my own calculations based on IDB publicly available data. Accessed on September 3, 2018, at https://www.iadb.org/en/projects. To find these data I filtered by sector (education) and status (implementation). This number is an underestimate, since I then identified projects that had “quality” in the title. It is likely that some projects had quality-improving components that were not reflected in the title.] The focus of this section is to answer the question, What did we know then about the quality of education in the region?

There is some disagreement on how to measure quality. There are two dominant ways it is addressed in the literature. The first refers to the capacity of the system to keep children on track to finish school (i.e., grade repetition). The second considers the level of learning—arguably the most important output of education systems. By looking at both of these issues in turn, I show two things. First, grade repetition across the entire region dropped substantially over time, even in the 1980s, suggesting that countries had found ways to limit grade repetition. Second, by the early 1990s there were simply no systematic, reliable data on learning outcomes in the region. In reviewing the evidence I show a mixed picture, product of data that was simply not reliable enough to make good judgments about the amount of learning done in the region.

First, let’s consider grade repetition. Figure 5 plots average grade repetition in primary school across Latin America in blue. The black points show the highest measured levels of grade repetition in the region for that year.^[Uneven availability of data across countries explains sharp movement from one year to the next.] The first conclusion to draw is that grade repetition clearly trends downward for the entire period. The second point is that this trend extends to the countries with the highest rate of repeaters. The drop is steep. In the period from 1980 to 1990 the percentage of grade repeaters among the countries with the highest repetition rates dropped by nearly 10 percentage points. I do not want to discount the fact that school repetition seems to be a region-wide problem; even a repetition rate of 15 percent is unacceptably high. Yet focusing on the headline results ignores the fact that the region improved with regard to repetition, even throughout the 1980s.

Quality is strongly associated with learning. The most prominent way to gauge student learning is by testing students, and one learns about the relative quality of a system by placing these results in comparative perspective. Latin American countries participated in only three testing initiatives prior to 1993.^[This review of these testing initiatives relies on the exposition in [@wolff_improving_1994], although I also consulted the primary sources they cite.] In 1990 Venezuela participated in the International Education Assessment (IEA) Study of Reading Literacy. In a sample of 32 school systems (mostly in developed countries) Venezuelan children scored lowest on a test of reading literacy. The results were discouraging: only 25% of students were able to answer half or more questions correctly; in some sections nearly a third of students scored as well as if they had randomly guessed [@elley_how_1992]. Second, in 1991 the Education Testing Service’s International Assessment of Educational Progress (IAEP) tested primary school students on math skills across nineteen countries, including two Brazilian cities: Sao Paulo and Fortaleza. The average scores of both cities were only marginally higher than those of Mozambique and lagged behind those of all other developing and developed countries [@lapointe_learning_1992].

The first true comparative testing effort that considered a broad swath of Latin American countries was the Trends in International Mathematics and Science Study (TIMSS) in 1992.^[Regional comparative testing took off later in the 1990s with the creation of the Latin American Laboratory for Assessment of the Quality of Education (LLECE in Spanish). The LLECE launched the First Regional Comparative and Explicative Study (PERCE in Spanish) in 1997.] The sample consisted of four types of schools from Argentina, Colombia, Costa Rica, the Dominican Republic, and Venezuela: elite private schools, elite public schools, lower class public schools, and rural public schools. However, the pilot study used a convenience rather than a representative sample.^[The distinction is that a representative sample would be able to speak to the broader population of schools and students, whereas a convenience sample may be biased in known and unknown ways, making it difficult to extrapolate any generalizations from the data.] The results with average scores from nationally representative studies in the United States and Thailand (as presented by @wolff_improving_1994) can be seen in table 1.

The headline result is that all sampled Latin American countries performed poorly compared to the United States and Thailand, except for, perhaps, Costa Rica. This result, however, masks large variation across sampled schools. In math, students attending elite schools, group A, outperform the average US and Thailand school by a fair amount. The story is weaker in science. Unsurprisingly, students in rural schools do significantly worse than the average student in US and Thailand schools.

The poor TIMSS results should have been a cause for concern. For one, they speak to inequality in learning across income groups and geographical space. Second, they show that Latin American students are learning less than developed countries but also a developing economy–Thailand. Because these results make intuitive sense–and possibly because they confirm the priors of education experts–education reform advocates harped on them. To give an example, in reviewing this very data, @wolff_improving_1994 conclude that “LAC countries do significantly worse in terms of achievement than the developed world, and also do worse than many Asian countries” (19).^[They do so even when they state clearly that these results are “illustrative only” (18).]

At the same time, the results from table 1 are highly qualified by the fact that they are not statistically representative of the Latin American student population. Without a representative sample, it is unclear what the main takeaway should be; it is plausible both that students did better or worse than TIMSS suggests.

The fact that Latin America had no reliable data on the quality of education is as important as the headline results from table 1. Despite an increased focus on the importance of learning beginning in the 1990s, this situation did not improve over the next ten years. In 2001, UNESCO’s Office for Latin American and the Caribbean concluded that “we do not yet have a time series of education achievement indicators that is sufficiently broad to adequately describe the behavior and trends of such indicators within countries in the region” [@unesco_state_2001 pp.10]. The consequences of this lack of information are stark. In the interim years Latin American countries had made all sorts of changes to their education systems, and yet, by the beginning of the millennium, policymakers across the region still had no tools to assess either the quality of education in their countries or the effectiveness of so-called quality-improving reforms!
Education reform in Latin America was predicated on improving the dismal coverage and quality of education. This is a premise commonly shared by political scientists studying reform efforts [@grindle_despite_2004;@corrales_politics_1999,;@kaufman_crucial_2004]. Yet the data covered in the two previous sections provide no clear evidence of a need for such reforms. When it came to the quality of education, in particular, policymakers were simply flying blind. Why, then, did Latin American countries reform their education systems?

# From Problems to Solutions: A Regression Approach

Thus far I have found no evidence of an overall deterioration in the coverage and quality of education in Latin America in the 1990s. Given that there is substantial variation in performance of quality and coverage across the region, it is possible that reforms were driven by countries that trailed their peers. For example, those countries with the lowest enrollment rates may have been under the most pressure to reform. Similarly, those countries that had participated in international testing initiatives may have been more likely to explore changes in their education systems. To a degree, this would be consistent with the notion that technical considerations propelled reform. In this section, I make use of regression tools to assess this possibility. To preview my findings, I do not find support for this argument.

To test this simple hypothesis I present a series of bivariate plots alongside regression lines, where applicable. To do so, I construct a small dataset with one observation per each of 18 countries. As a dependent variable I use the number of education reform initiatives each country deployed in the 1990s. These data come from @grindle_despite_2004 and cover everything from curriculum changes to changes in governance. Crucially, this includes reforms whether or not they were successfully implemented, thus avoiding any bias that might arise from conflating the origins of political reform with the politics of implementing policy. As independent variables, plotted on the x-axis, I use 1990 data on 1) enrollment rates, 2) average years of schooling, 3) enrollment rates for women, and 4) a dummy variable indicating whether a country participated in the first TIMMS. The first three I take from UNESCO statistics, whereas the last is constructed based on data from @lapointe_learning_1992. I plot the dependent variable on the y-axis against each of the independent variables on the x-axis in figure 6.

Figure 6 has four panels, one for each of the independent variables. The first three panels, moving clockwise from the top left panel, contain both a (linear) regression line and a LOESS line, in blue and red, respectively. I also place the country name abbreviation near the corresponding dot. The plots generally tell the same story. Consider first gross enrollment rates: aside from Guatemala and perhaps Bolivia, the countries doing the most reforms have above average enrollment rates. Next, consider the plot on average school years. Countries with the fewest average years of schooling seem as likely as those with the most years of schooling to commit to reforms. It is those countries near the regional average that seem to be doing most of the work. Looking at those countries where women have completed primary schooling reveals that as the share of educated females increased, the number of reforms dropped. However, this line seems to be driven in part by Bolivia; the LOESS line is rather flat after Bolivia. Finally, participating in TIMSS seems to have no clear relationship to the number of reforms.

These plots have limitations; they are simple bivariate correlations with no covariates. While they do not claim to show a causal relationship, they do show a clear story. By and large, reforms were not happening in those countries with the weakest education systems.

# Moving the Literature Forward

@bruns_managing_2016 have recently concluded that the political science literature on education reform is “under researched and under analyzed” (p. 2). The unfortunate consequence of this is that we take as a given the premises of the few seminal works in the area. This short piece challenges conventional wisdom by refuting the notion that there was a deep crisis in education in Latin America in 1990. By plotting the trajectory of key indicators, I show that on a range of issues, education systems across the region were succeeding or at least not collapsing. If Latin American education was not in dire need of reform, why did so many countries reform their education systems?

The most innocuous possibility is that politicians were truly convinced that there was a need to reform education. This could have been a result of their own experiences or perhaps because reform advocates convinced them that the time was right for change. This is a plausible explanation and one that deserve sustained attention from political scientists. At the same time, recent contributions to the literature on social policy expansion suggest that political and electoral incentives can account for dramatic changes in the provision of public services.
One possibility is that regime type matters in the politics of education [@ansell_political_2013]. For example, politicians might be compelled to reform or expand education when the organized poor demand it [@kosack_education_2012;@dion_workers_2010]. While this might explain reform in some regions of the world, Latinobarometro data from the 1990s reveal that most citizens´ in most countries of the region had a favorable view of primary education. On the other hand, elites may feel compelled to expand public services like education to traditionally underserved outsiders for electoral reasons [@garay_social_2016]. Yet political outsiders in Latin America have generally come to expect very little from the state [@holland_diminished_2018]. Moreover, quality-improving reforms are not highly visible, casting doubt on the idea that such initiatives would yield votes at the ballot box. In short, neither a bottoms-up nor a top-down electoral explanation accounts well for why politicians were willing to transform the education sector.

These contributions raise the possibility that reforming education might serve some other, unseen political logic. Figure 1 showcases the popularity of education governance reforms in the 1990s. Many of these initiatives entailed decentralizing the provision of public education by giving subnational units of government more responsibility over financing or administering public education. Perhaps politicians latched on to the framing of “education in crisis” to provide cover for unpopular policies that might strengthen their hand down the road.  The plausible political logics are numerous: decentralizing education might 1) protect richer subnational units from paying for the education of poorer areas, 2) break up teachers’ unions when these are allied with the opposition, 3) lower the taxes of allies and limit redistribution towards groups in the opposition’s coalition, etc. The logic might be similar to the argument suggesting that political decentralization in Latin America was a political strategy by incumbents about to lose a general election [@oneill_decentralizing_2005]. Understanding the political origins of education reform requires a serious engagement with these arguments.

Another possibility emerges when we think about timing. Why did so many countries select to reform at the same time? Figure 1 hints at the fact that the decentralization of governance in education might be explained in part by a diffusion process. The fact that diffusion is, from the vantage point of political science, not a clearer part of the politics of education in the region is surprising given the amount of literature exploring social policy borrowing in Latin America [@brooks_globalization_2007; @weyland_bounded_2006; @borges_neoliberalism_2018]. The case of education reform provides an opportunity to hypothesize and test the mechanisms through which diffusion operates in the Latin American context. This might shed light on the role of international organizations, the networks of policymakers, and trends in international development. In this sense, education researchers are far ahead of comparativists, placing greater analytic weight on “the international” than our discipline [@edwards_jr_trajectory_2017;@mundy_world_2016].

Reversing the notion that reform was needed and pursued on purely technical grounds is an important point with implications for how we understand education reform and social policy more broadly. Where the existing literature emphasizes the role that well-organized interests (typically unions) play in blocking reforms [@corrales_politics_1999; @graham_improving_1999;@bonilla_pensiones_1998; @moe_comparative_2016], a new profitable line of inquiry might pay closer attention to the incentives that motivate governments to engage in extensive reforms of a sensitive sector in the first place. This might provide more leverage to understand why some of these reforms succeeded and others failed. In sum, to answer the question of “What explains why and how Latin American countries reformed their education systems?” we really must begin with the question of what government leaders believed they would gain if they advanced reforms to their education systems. Because this entails placing political incentives front and center, political scientists should be engaging with, learning from, and on occasion leading, the growing number of education researchers examining these topics [@williams_political_2017; @verger_why_2014].

\newpage 

# References 
